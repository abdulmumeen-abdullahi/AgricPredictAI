# -*- coding: utf-8 -*-
"""Crop_Disease_Detection

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NpA23k8u_hHl3Mn6smWNwZukVK2Qh8H3
"""

import streamlit as st
import torch
import os
import gdown
from PIL import Image
import torchvision.transforms as transforms
import openai
from openai import OpenAI, RateLimitError

# ----------------- CONFIG -----------------
st.set_page_config(page_title="NaijaFarmConsultAI - Crop Disease", layout="centered")

# Load OpenAI Key securely
os.environ['OPENAI_API_KEY'] = st.secrets['OPENAI_API_KEY']
openai.api_key = st.secrets["OPENAI_API_KEY"]

# ----------------- MODEL PATHS -----------------
DISEASE_MODEL_ID = "1O-K4s3tv3WTSouhUksPDA5u6gNQ_d0j1"
DISEASE_MODEL_PATH = "best_crop_disease_model.pt"

DISEASE_CLASSES = [
    'Corn___Common_Rust', 'Corn___Gray_Leaf_Spot', 'Corn___Healthy', 'Corn___Northern_Leaf_Blight',
    'Potato___Early_Blight', 'Potato___Healthy', 'Potato___Late_Blight',
    'Rice___Brown_Spot', 'Rice___Healthy', 'Rice___Leaf_Blast', 'Rice___Neck_Blast',
    'Sugarcane__Bacterial_Blight', 'Sugarcane__Healthy', 'Sugarcane__Red_Rot',
    'Wheat___Brown_Rust', 'Wheat___Healthy', 'Wheat___Yellow_Rust'
]

# ----------------- MODEL LOADER -----------------
def download_model():
    if not os.path.exists(DISEASE_MODEL_PATH):
        url = f"https://drive.google.com/uc?id={DISEASE_MODEL_ID}"
        gdown.download(url, DISEASE_MODEL_PATH, quiet=False)

@st.cache_resource
def load_model():
    download_model()
    model = torch.load(DISEASE_MODEL_PATH, map_location=torch.device("cpu"))
    model.eval()
    return model

def preprocess_image(image_file):
    image = Image.open(image_file).convert("RGB")
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor()
    ])
    return transform(image).unsqueeze(0)

def predict_disease(image_file):
    model = load_model()
    input_tensor = preprocess_image(image_file)
    outputs = model(input_tensor)
    _, predicted = torch.max(outputs, 1)
    return DISEASE_CLASSES[predicted.item()]

# ----------------- GPT CONTEXT -----------------
system_prompt = [
    {"role": "system", "content": """
        You are NaijaFarmConsultAI, a friendly and knowledgeable agricultural extension officer in Nigeria. 
        You assist farmers with advice about crop diseases, management practices, and prevention. 
        Use simple, local, and clear terms when explaining plant diseases. Maintain a warm tone like a trusted advisor.

        RESPONSE FLOW:
        1. Start with a friendly greeting and confirmation of the crop disease identified.
        2. Explain what the disease is and its effect on the crop.
        3. Recommend 2‚Äì3 actionable treatment or control steps.
        4. Give a quick prevention tip for the future.
        5. Encourage the farmer to ask for more help if needed.
    """}
]

def get_completions_from_messages(messages, model="gpt-3.5-turbo", stream=True):
    client = OpenAI()
    try:
        return client.chat.completions.create(
            messages=messages,
            model=model,
            stream=stream
        )
    except RateLimitError:
        st.error("üö´ Rate limit reached. Please wait a few seconds and try again.")
        return None
    except Exception as e:
        st.error(f"‚ùå Unexpected error: {e}")
        return None

# ----------------- STREAMLIT APP -----------------
def main():
    st.title("NaijaFarmConsultAI - Crop Disease")
    st.write("Upload an image of your crop to detect disease and chat with NaijaFarmConsultAI for expert advice.")

    if "openai_model" not in st.session_state:
        st.session_state["openai_model"] = "gpt-3.5-turbo"

    if "messages" not in st.session_state:
        st.session_state.messages = system_prompt.copy()

    uploaded_file = st.file_uploader("Upload a crop image", type=["jpg", "jpeg", "png"])

    if uploaded_file:
        st.image(uploaded_file, caption="Your Uploaded Image", use_column_width=True)

        if st.button("Diagnose Disease"):
            with st.spinner("Running diagnosis..."):
                disease_prediction = predict_disease(uploaded_file)
            st.success(f"Predicted Disease: **{disease_prediction}**")

            st.session_state.messages.append({"role": "user", "content": f"What should I do for: {disease_prediction}?"})

            with st.chat_message("assistant"):
                message_placeholder = st.empty()
                full_response = ""

                response_stream = get_completions_from_messages(
                    messages=st.session_state.messages,
                    model=st.session_state["openai_model"],
                    stream=True
                )

                if response_stream:
                    for chunk in response_stream:
                        if chunk.choices[0].delta.content:
                            full_response += chunk.choices[0].delta.content
                            message_placeholder.markdown(full_response + "‚ñå")
                    message_placeholder.markdown(full_response)
                    st.session_state.messages.append({"role": "assistant", "content": full_response})
                else:
                    st.info("AI could not respond right now. Please try again in a few seconds.")

    # --- Chat Input for Follow-ups ---
    if user_prompt := st.chat_input("Ask NaijaFarmConsultAI anything about your crop health..."):
        st.session_state.messages.append({"role": "user", "content": user_prompt})

        with st.chat_message("user"):
            st.markdown(user_prompt)

        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            full_response = ""

            response_stream = get_completions_from_messages(
                messages=st.session_state.messages,
                model=st.session_state["openai_model"],
                stream=True
            )

            if response_stream:
                for chunk in response_stream:
                    if chunk.choices[0].delta.content:
                        full_response += chunk.choices[0].delta.content
                        message_placeholder.markdown(full_response + "‚ñå")
                message_placeholder.markdown(full_response)
                st.session_state.messages.append({"role": "assistant", "content": full_response})
            else:
                st.info("AI could not respond right now. Please try again in a few seconds.")

    st.markdown("---")
    st.caption("Powered by PyTorch + EfficientNet + OpenAI | Built with ‚ù§Ô∏è for Nigerian Farmers")

if __name__ == "__main__":
    main()
